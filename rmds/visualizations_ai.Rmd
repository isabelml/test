---
title: "Visualizations and text analysis"
author: "Isabel Molero López"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Introduction

This document shows the code needed to create a line graph showing the evolution 
of the articles published by the two newspapers (El Mundo and elDiario.es) on 
artificial intelligence from 2014 to 2023. In addition, a text analysis is also 
performed for which several visualizations are included. The code needed to 
extract and clean the data used in this file is located in the same GitHub 
repository.

# 2. Load libraries
```{r message=FALSE, warning=FALSE}
# General libraries
library(tidyverse)

# To perform text analysis:
library(stopwords)
library(tidytext)
library(textdata)
library(syuzhet)

# To make plots:
library(ggplot2)
library(scales)
library(ggpubr)
library(RColorBrewer)
library(RColorBrewer)
library(wordcloud)
library(reshape2)
library(forcats)
library(igraph)
```

# 3. Read data
```{r message=FALSE}
eldiario_all <- read_csv("../data/eldiario_all.csv")
elmundo_all <- read_csv("../data/elmundo_all.csv")
```

# 4. Line graph: number of news articles published over time

## Create a column with the month and year

```{r}
eldiario_all$year_month <- format(eldiario_all$date, "%Y-%m")
elmundo_all$year_month <- format(elmundo_all$date, "%Y-%m")
```

## Filter only the articles which contains in the text the words "inteligencia artificial"

```{r}
eldiario_all_filter <- eldiario_all %>% 
  filter(str_detect(text, regex("inteligencia artificial", ignore_case = TRUE)))

elmundo_all_filter <- elmundo_all %>% 
  filter(str_detect(text, regex("inteligencia artificial", ignore_case = TRUE))) %>% 
  filter(!is.na(date)) # remove NAs in the column "date"
```

## Clean dates

Now I am going to set the same minimum and maximum date of publication of 
articles for both datasets:

```{r}
min(eldiario_all_filter$date)
min(elmundo_all_filter$date)

max(eldiario_all_filter$date)
max(elmundo_all_filter$date)
```
```{r}
eldiario_all_filter <- eldiario_all_filter %>% 
  filter(date >= "2014-07-28") %>% 
  filter(date <= "2023-04-30")

elmundo_all_filter <- elmundo_all_filter %>% 
  filter(date <= "2023-04-30")
```

## Join both dataframes

```{r}
final_df <- eldiario_all_filter %>% 
  mutate(newspaper = "elDiario.es") %>% 
  bind_rows(elmundo_all_filter %>%
              mutate(newspaper = "elmundo.es")) 

final_df <- final_df[!grepl("^https://www.elmundo.es/ofertas-regalos", final_df$link), ]
```

### Table with the number of articles published by year

```{r}
final_df %>% 
  filter(newspaper == "elDiario.es") %>% 
  mutate(year = year(date)) %>% 
  count(year)

final_df %>% 
  filter(newspaper == "elmundo.es") %>% 
  mutate(year = year(date)) %>% 
  count(year)
```


## Plot

### Create new column

```{r}
library(RColorBrewer)

# Supongamos que tu dataframe se llama 'final_df'
# Asegúrate de que 'year_month' sea de tipo Date o POSIXct para poder realizar operaciones con fechas correctamente

# Crear una nueva columna 'year_month' en formato Date
final_df <- final_df %>%
  mutate(year_month = ym(year_month))

# Crear una nueva columna 'cuatrimestre_anio' basada en 'year_month'
final_df <- final_df %>%
  mutate(q_year = case_when(
    month(year_month) %in% c(1, 2, 3, 4) ~ paste0("Q1 ", format(year_month, "%Y")),
    month(year_month) %in% c(5, 6, 7, 8) ~ paste0("Q2 ", format(year_month, "%Y")),
    month(year_month) %in% c(9, 10, 11, 12) ~ paste0("Q3 ", format(year_month, "%Y"))
  ))

# Ordenar las etiquetas en orden cronológico
final_df <- final_df %>%
  mutate(q_year = reorder(q_year, year_month))
```

### Create the plot with ggplot2

```{r}
# Crear el gráfico de líneas por cuatrimestres y periódicos
ggplot(final_df, aes(x = q_year, group = newspaper, color = newspaper)) +
  geom_line(stat = "count", position = "identity", linewidth = 0.8) +
  labs(title = "Number of articles published per quarter and year",
       subtitle = "2014-2023") +
  scale_x_discrete(breaks = final_df$q_year[grepl("Q1", final_df$q_year)]) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title = element_blank(),
        legend.text = element_text(family = "Times New Roman", size = 11),
        legend.position = "top",
        legend.justification = "left",
        legend.box.margin = margin(l = -12),
        legend.title = element_blank(),
        plot.title = element_text(family = "Times New Roman", size = 14, face = "bold"),
        plot.subtitle = element_text(family = "Times New Roman", size = 12)) +
  scale_color_brewer(palette = "Dark2") +
  # geom_vline(xintercept = "Q1 2022", linetype = "dashed", color = "black")
  geom_segment(aes(x = "Q1 2022", xend = "Q1 2022", y = 0, yend = 110), 
               size = 0.3, linetype = "dashed", colour = "black", alpha = 0.02) +
  geom_segment(aes(x = "Q1 2016", xend = "Q1 2016", y = 0, yend = 125), 
               size = 0.3, linetype = "dashed", colour = "black", alpha = 0.02) +
  geom_segment(aes(x = "Q1 2021", xend = "Q1 2021", y = 0, yend = 125), 
               size = 0.3, linetype = "dashed", colour = "black", alpha = 0.02) +
  geom_segment(aes(x = "Q2 2022", xend = "Q2 2022", y = 0, yend = 130), 
               size = 0.3, linetype = "dashed", colour = "black", alpha = 0.02) +
  geom_segment(aes(x = "Q3 2015", xend = "Q3 2015", y = 0, yend = 125), 
               size = 0.3, linetype = "dashed", colour = "black", alpha = 0.02) +
  annotate("text", x = "Q1 2022", y = 120, label = "ChatGPT   ", family = "Times New Roman") +
  annotate("text", x = "Q1 2021", y = 135, label = "DALL-E", family = "Times New Roman") +
  annotate("text", x = "Q2 2022", y = 140, label = "Midjourney", family = "Times New Roman") +
  annotate("text", x = "Q3 2015", y = 140, label = "AlphaGo \nMETA AI", family = "Times New Roman") 

final_df %>% 
  count(newspaper, q_year) 
```

# Text-analysis visualizations

## Take a look to the text

```{r}
head(final_df %>% filter(newspaper == "elDiario.es") %>%  select(text))
```

```{r}
head(final_df %>% filter(newspaper == "elmundo.es") %>%  select(text))
```

## Remove first line in elDiario.es "EFE" news

```{r}
head(final_df %>% filter(newspaper == "elDiario.es") %>%  select(text))
```


```{r}
final_df_test <- final_df %>% 
  filter(!str_detect(text, regex("(EFE).", ignore_case = FALSE)))

final_df_test2 <- final_df %>% 
  filter(str_detect(text, regex("(EFE).", ignore_case = FALSE))) %>% 
  mutate(text = sub("^[^.]*\\.", "", text))

# Join the dataframes again
final_df <- final_df_test %>% 
  bind_rows(final_df_test2)

rm(final_df_test, final_df_test2)

head(final_df %>% filter(newspaper == "elDiario.es") %>%  select(text))
```

## Let's break the text into words

```{r}
tokens <- final_df %>%
  unnest_tokens(word, text, drop = F, to_lower = T) %>% 
  # I remove the date column:
  select(word, date, newspaper, q_year)

tokens
```

## Filter stop words

Then I eliminate the words that are not useful for the analysis with the 
"stopwords()" library in Spanish. In addition, I have the word "si" which was 
not included but which I consider has no value for the analysis.

```{r}
spanish_stopwords <- stopwords("es")
additional_stopwords <- c("si","ser","inteligencia","artificial","además", "ia", "así", "según",
                          "cada", "dos", "descuento")
spanish_stopwords <- c(spanish_stopwords, additional_stopwords)

tokens <- tokens %>% 
  anti_join(data.frame(word = spanish_stopwords), by = "word") %>% 
  filter(word != "si" & word != "ser" & word != "inteligencia" & word != "artificial" & word != "además")

tokens
```

## Counting word frequencies

```{r}
tokens %>%
  count(word, sort = TRUE) 
```

### Visualize word frequencies

The following graphs shows the frequency of the most repeated words.

#### elDiario.es

```{r}
tokens %>%
  filter(newspaper == "elDiario.es") %>% 
  count(word, sort = TRUE) %>%
  #only words mentioned over 1000 times in the speeches
  filter(n > 650) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col(fill = "#ff5252") +
  labs(title = "Word frequency in articles on artificial intelligence published in elDiario.es",
       subtitle = "2014-2023",
       caption = "Source: elDiario.es",
    y = NULL,
    x = NULL) +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_text(family = "Times New Roman", size = 14, face = "bold",
                                  margin = margin(0, 0, 0, 0)),
        plot.subtitle = element_text(family = "Times New Roman", size = 12,
                                     margin = margin(5, 0, 20, 0),),
        axis.text.y = element_text(hjust = 0, family = "Times New Roman", size = 11,
                                   colour = "black"))
```
#### El Mundo

```{r}
tokens %>%
  filter(newspaper == "elmundo.es") %>% 
  count(word, sort = TRUE) %>%
  #only words mentioned over 1000 times in the speeches
  filter(n > 1000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col(fill = "#ff5252") +
  labs(title = "Word frequency in articles on artificial intelligence published in elmundo.es",
       subtitle = "2014-2023",
       caption = "Source: elmundo.es",
    y = NULL,
    x = NULL) +
  theme_minimal() +
  theme(plot.title.position = "plot",
        plot.title = element_text(family = "Times New Roman", size = 14, face = "bold",
                                  margin = margin(0, 0, 0, 0)),
        plot.subtitle = element_text(family = "Times New Roman", size = 12,
                                     margin = margin(5, 0, 20, 0),),
        axis.text.y = element_text(hjust = 0, family = "Times New Roman", size = 11,
                                   colour = "black"))
```

### Comparing word frequencies across two different years

```{r}
library(tidyr)

frequency <- tokens %>% 
  mutate(word = str_extract(word, "\\b\\p{L}+\\b")) %>%
  count(newspaper, word) %>%
  group_by(newspaper) %>%
  mutate(proportion = n / sum(n)) %>% 
  filter(n > 15) %>% 
  select(-n) %>% 
  pivot_wider(names_from = newspaper, values_from = proportion) %>%
  pivot_longer(`elDiario.es`,
               names_to = "newspaper", values_to = "proportion")

frequency
```

```{r warning=FALSE}

frequency %>% 
  ggplot(aes(x = proportion, y = `elmundo.es`, 
                      color = abs(`elmundo.es` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 0.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 0.5) +
  theme_minimal() +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "darkslategray4", high = "gray75") +
  theme(legend.position="none") +
  labs(y = "elmundo.es", x = "elDiario.es") 
```

```{r}

```

